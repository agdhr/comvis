{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DATASET\n",
    "\n",
    "import pandas as pd\n",
    "# --- Import Dataset 1\n",
    "dataset = pd.read_csv('11-df_coffee/dataset.csv')\n",
    "dataset.head(10)\n",
    "# --- Changing pandas dataframe to numpy array to determine X and y variables\n",
    "X = dataset.iloc[:,:85].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "(_,Xcol) = X.shape\n",
    "num_features = Xcol\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# --- Data Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "# --- Determine classes (y variable) in training set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#ohe = OneHotEncoder()\n",
    "#y = ohe.fit_transform(y).toarray()\n",
    "# --- Separating the dataset into training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ML Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "clf_gnb = GaussianNB(priors=None,\n",
    "                     var_smoothing=1e-09)\n",
    "clf_lr = LogisticRegression(penalty='l2',\n",
    "                            dual=False,\n",
    "                            tol=0.0001,\n",
    "                            C=1.0,\n",
    "                            fit_intercept=True,\n",
    "                            intercept_scaling=1,\n",
    "                            class_weight=None,\n",
    "                            random_state=None,\n",
    "                            solver='lbfgs',\n",
    "                            max_iter=100,\n",
    "                            multi_class='auto',\n",
    "                            verbose=0,\n",
    "                            warm_start=False,\n",
    "                            n_jobs=None,\n",
    "                            l1_ratio=None)\n",
    "clf_dt = DecisionTreeClassifier(criterion='entropy',    # 'gini'\n",
    "                            splitter='best',\n",
    "                            max_depth=5,             #None\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=10,         #1 - default\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            max_features=None,\n",
    "                            random_state=None,\n",
    "                            max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.0,\n",
    "                            class_weight=None,\n",
    "                            ccp_alpha=0.0)\n",
    "clf_rf = RandomForestClassifier(n_estimators=100,\n",
    "                                criterion='gini',\n",
    "                                max_depth=None,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=16,    # default = 1\n",
    "                                min_weight_fraction_leaf=0.0,\n",
    "                                max_features='sqrt',\n",
    "                                max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                bootstrap=True,\n",
    "                                oob_score=False,\n",
    "                                n_jobs=None,\n",
    "                                random_state=None,\n",
    "                                verbose=0,\n",
    "                                warm_start=False,\n",
    "                                class_weight=None,\n",
    "                                ccp_alpha=0.0,\n",
    "                                max_samples=None)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5,\n",
    "                               weights='uniform',\n",
    "                               algorithm='auto',\n",
    "                               leaf_size=30,\n",
    "                               p=2,\n",
    "                               metric='minkowski',\n",
    "                               metric_params=None,\n",
    "                               n_jobs=None)\n",
    "clf_svm = svm.SVC(C=1.0,\n",
    "                  kernel='linear',      # default rbf\n",
    "                  degree=3,\n",
    "                  gamma='scale',\n",
    "                  coef0=0.0,\n",
    "                  shrinking=True,\n",
    "                  probability=True,     # default False\n",
    "                  tol=0.001,\n",
    "                  cache_size=200,\n",
    "                  class_weight=None,\n",
    "                  verbose=False,\n",
    "                  max_iter=-1,\n",
    "                  decision_function_shape='ovr',\n",
    "                  break_ties=False,\n",
    "                  random_state=None)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GAUSSIAN NAIVE-BAYES\n",
    "\n",
    "# --- fit the model\n",
    "model_gnb = clf_gnb.fit(X_train, y_train)\n",
    "pred_gnb = model_gnb.predict(X_test)\n",
    "# --- Model Accuracy\n",
    "gnb_acc = accuracy_score(pred_gnb, y_test)\n",
    "print('Model Accuracy: {:.5f}'.format(gnb_acc))\n",
    "# --- Confusion Matrix\n",
    "gnb_conmat = confusion_matrix(pred_gnb, y_test)\n",
    "print(gnb_conmat)\n",
    "display = ConfusionMatrixDisplay(gnb_conmat,display_labels=[\"ARABICA\", \"ROBUSTA\"])\n",
    "display.plot(cmap=\"YlGnBu\")\n",
    "display.figure_.suptitle('Confusion Matrix')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "gnb_TP = gnb_conmat[0,0]\n",
    "gnb_TN = gnb_conmat[1,1]\n",
    "gnb_FP = gnb_conmat[0,1]\n",
    "gnb_FN = gnb_conmat[1,0]\n",
    "\n",
    "# --- Performance Metrics\n",
    "gnb_acc = (gnb_TP+gnb_TN)/ float(gnb_TP+gnb_TN+gnb_FP+gnb_FN)\n",
    "print('GNB Accuracy : {0:0.5f}'.format(gnb_acc))\n",
    "gnb_error = (gnb_FP+gnb_FN)/ float(gnb_TP+gnb_TN+gnb_FP+gnb_FN)\n",
    "print('GNB Error : {0:0.5f}'.format(gnb_error))\n",
    "gnb_spec = gnb_TN/float(gnb_TN+gnb_FP)\n",
    "print('GNB Specificity : {0:0.5f}'.format(gnb_spec))\n",
    "gnb_prec = gnb_TP/float(gnb_TP+gnb_FP)\n",
    "print('GNB Precision : {0:0.5f}'.format(gnb_prec))\n",
    "gnb_recall = gnb_TP/float(gnb_TP+gnb_FN)\n",
    "print('GNB Recall/Sensitivity : {0:0.5f}'.format(gnb_recall))\n",
    "gnb_f1s = 2*gnb_recall*gnb_prec/float(gnb_recall+gnb_prec)\n",
    "print('GNB F1-Score : {0:0.5f}'.format(gnb_f1s))\n",
    "gnb_tpr = gnb_TP/float(gnb_TP+gnb_FN)\n",
    "print('GNB True Positive Rate : {0:0.5f}'.format(gnb_tpr))\n",
    "gnb_fpr = gnb_FP/float(gnb_FP+gnb_TN)\n",
    "print('GNB False Positive Rate : {0:0.5f}'.format(gnb_fpr))\n",
    "gnb_res = classification_report(pred_gnb, y_test)\n",
    "print(gnb_res)\n",
    "gnb_accuracy = metrics.accuracy_score(y_test, pred_gnb)\n",
    "gnb_precision = metrics.precision_score(y_test, pred_gnb)\n",
    "gnb_sensitivity_recall = metrics.recall_score(y_test, pred_gnb)\n",
    "gnb_specificity = metrics.recall_score(y_test, pred_gnb, pos_label=0)\n",
    "gnb_F1_score = metrics.f1_score(y_test, pred_gnb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# fit the model\n",
    "model_lr = clf_lr.fit(X_train, y_train)\n",
    "pred_lr = model_lr.predict(X_test)\n",
    "# --- Model Accuracy\n",
    "lr_acc = accuracy_score(pred_lr, y_test)\n",
    "print('Model Accuracy: {:.5f}'.format(lr_acc))\n",
    "# --- Confusion Matrix\n",
    "lr_conmat = confusion_matrix(pred_lr, y_test)\n",
    "print(lr_conmat)\n",
    "display = ConfusionMatrixDisplay(lr_conmat, display_labels=[\"ARABICA\", \"ROBUSTA\"])\n",
    "display.plot(cmap=\"YlGnBu\")\n",
    "display.figure_.suptitle('Confusion Matrix')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "lr_TP = lr_conmat[0,0]\n",
    "lr_TN = lr_conmat[1,1]\n",
    "lr_FP = lr_conmat[0,1]\n",
    "lr_FN = lr_conmat[1,0]\n",
    "\n",
    "# --- Performance Metrics\n",
    "lr_acc = (lr_TP+lr_TN)/ float(lr_TP+lr_TN+lr_FP+lr_FN)\n",
    "print('LR Accuracy : {0:0.5f}'.format(lr_acc))\n",
    "lr_error = (lr_FP+lr_FN)/ float(lr_TP+lr_TN+lr_FP+lr_FN)\n",
    "print('LR Error : {0:0.5f}'.format(lr_error))\n",
    "lr_spec = lr_TN/float(lr_TN+lr_FP)\n",
    "print('LR Specificity : {0:0.5f}'.format(lr_spec))\n",
    "lr_prec = lr_TP/float(lr_TP+lr_FP)\n",
    "print('LR Precision : {0:0.5f}'.format(lr_prec))\n",
    "lr_recall = lr_TP/float(lr_TP+lr_FN)\n",
    "print('LR Recall/Sensitivity : {0:0.5f}'.format(lr_recall))\n",
    "lr_f1s = 2*lr_recall*lr_prec/float(lr_recall+lr_prec)\n",
    "print('LR F1-Score : {0:0.5f}'.format(lr_f1s))\n",
    "lr_tpr = lr_TP/float(lr_TP+lr_FN)\n",
    "print('LR True Positive Rate : {0:0.5f}'.format(lr_tpr))\n",
    "lr_fpr = lr_FP/float(lr_FP+lr_TN)\n",
    "print('LR False Positive Rate : {0:0.5f}'.format(lr_fpr))\n",
    "lr_res = classification_report(pred_lr, y_test)\n",
    "print(lr_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "# fit the model\n",
    "model_dt = clf_dt.fit(X_train, y_train)\n",
    "pred_dt = model_dt.predict(X_test)\n",
    "# --- Model Accuracy\n",
    "dt_acc = accuracy_score(pred_dt, y_test)\n",
    "print('Model Accuracy: {:.5f}'.format(dt_acc))\n",
    "# --- Confusion Matrix\n",
    "dt_conmat = confusion_matrix(pred_dt, y_test)\n",
    "print(dt_conmat)\n",
    "display = ConfusionMatrixDisplay(dt_conmat, display_labels=[\"ARABICA\", \"ROBUSTA\"])\n",
    "display.plot(cmap=\"YlGnBu\")\n",
    "display.figure_.suptitle('Confusion Matrix')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "dt_TP = dt_conmat[0,0]\n",
    "dt_TN = dt_conmat[1,1]\n",
    "dt_FP = dt_conmat[0,1]\n",
    "dt_FN = dt_conmat[1,0]\n",
    "\n",
    "# --- Performance Metrics\n",
    "dt_acc = (dt_TP+dt_TN)/ float(dt_TP+dt_TN+dt_FP+dt_FN)\n",
    "print('DT Accuracy : {0:0.5f}'.format(dt_acc))\n",
    "dt_error = (dt_FP+dt_FN)/ float(dt_TP+dt_TN+dt_FP+dt_FN)\n",
    "print('DT Error : {0:0.5f}'.format(dt_error))\n",
    "dt_spec = dt_TN/float(dt_TN+dt_FP)\n",
    "print('DT Specificity : {0:0.5f}'.format(dt_spec))\n",
    "dt_prec = dt_TP/float(dt_TP+dt_FP)\n",
    "print('DT Precision : {0:0.5f}'.format(dt_prec))\n",
    "dt_recall = dt_TP/float(dt_TP+dt_FN)\n",
    "print('DT Recall/Sensitivity : {0:0.5f}'.format(dt_recall))\n",
    "dt_f1s = 2*dt_recall*dt_prec/float(dt_recall+dt_prec)\n",
    "print('DT F1-Score : {0:0.5f}'.format(dt_f1s))\n",
    "dt_tpr = dt_TP/float(dt_TP+dt_FN)\n",
    "print('DT True Positive Rate : {0:0.5f}'.format(dt_tpr))\n",
    "dt_fpr = dt_FP/float(dt_FP+dt_TN)\n",
    "print('DT False Positive Rate : {0:0.5f}'.format(dt_fpr))\n",
    "dt_res = classification_report(pred_dt, y_test)\n",
    "print(dt_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "# fit the model\n",
    "model_rf = clf_rf.fit(X_train, y_train)\n",
    "pred_rf = model_rf.predict(X_test)\n",
    "# --- Model Accuracy\n",
    "rf_acc = accuracy_score(pred_rf, y_test)\n",
    "print('Model Accuracy: {:.5f}'.format(rf_acc))\n",
    "# --- Confusion Matrix\n",
    "rf_conmat = confusion_matrix(pred_rf, y_test)\n",
    "print(rf_conmat)\n",
    "display = ConfusionMatrixDisplay(rf_conmat, display_labels=[\"ARABICA\", \"ROBUSTA\"])\n",
    "display.plot(cmap=\"YlGnBu\")\n",
    "display.figure_.suptitle('Confusion Matrix')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "rf_TP = rf_conmat[0,0]\n",
    "rf_TN = rf_conmat[1,1]\n",
    "rf_FP = rf_conmat[0,1]\n",
    "rf_FN = rf_conmat[1,0]\n",
    "\n",
    "# --- Performance Metrics\n",
    "rf_acc = (rf_TP+rf_TN)/ float(rf_TP+rf_TN+rf_FP+rf_FN)\n",
    "print('RF Accuracy : {0:0.5f}'.format(rf_acc))\n",
    "rf_error = (rf_FP+rf_FN)/ float(rf_TP+rf_TN+rf_FP+rf_FN)\n",
    "print('RF Error : {0:0.5f}'.format(rf_error))\n",
    "rf_spec = rf_TN/float(rf_TN+rf_FP)\n",
    "print('RF Specificity : {0:0.5f}'.format(rf_spec))\n",
    "rf_prec = rf_TP/float(rf_TP+rf_FP)\n",
    "print('RF Precision : {0:0.5f}'.format(rf_prec))\n",
    "rf_recall = rf_TP/float(rf_TP+rf_FN)\n",
    "print('RF Recall/Sensitivity : {0:0.5f}'.format(rf_recall))\n",
    "rf_f1s = 2*rf_recall*rf_prec/float(rf_recall+rf_prec)\n",
    "print('RF F1-Score : {0:0.5f}'.format(rf_f1s))\n",
    "rf_tpr = rf_TP/float(rf_TP+rf_FN)\n",
    "print('RF True Positive Rate : {0:0.5f}'.format(rf_tpr))\n",
    "rf_fpr = rf_FP/float(rf_FP+rf_TN)\n",
    "print('RF False Positive Rate : {0:0.5f}'.format(rf_fpr))\n",
    "rf_res = classification_report(pred_rf, y_test)\n",
    "print(rf_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_knn = clf_knn.fit(X_train, y_train)\n",
    "pred_knn = model_knn.predict(X_test)\n",
    "# --- Model Accuracy\n",
    "knn_acc = accuracy_score(pred_knn, y_test)\n",
    "print('Model Accuracy: {:.5f}'.format(knn_acc))\n",
    "# --- Confusion Matrix\n",
    "knn_conmat = confusion_matrix(pred_knn, y_test)\n",
    "print(knn_conmat)\n",
    "display = ConfusionMatrixDisplay(knn_conmat, display_labels=[\"ARABICA\", \"ROBUSTA\"])\n",
    "display.plot(cmap=\"YlGnBu\")\n",
    "display.figure_.suptitle('Confusion Matrix')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "knn_TP = knn_conmat[0,0]\n",
    "knn_TN = knn_conmat[1,1]\n",
    "knn_FP = knn_conmat[0,1]\n",
    "knn_FN = knn_conmat[1,0]\n",
    "\n",
    "# --- Performance Metrics\n",
    "knn_acc = (knn_TP+knn_TN)/ float(knn_TP+knn_TN+knn_FP+knn_FN)\n",
    "print('KNN Accuracy : {0:0.5f}'.format(knn_acc))\n",
    "knn_error = (knn_FP+knn_FN)/ float(knn_TP+knn_TN+knn_FP+knn_FN)\n",
    "print('KNN Error : {0:0.5f}'.format(knn_error))\n",
    "knn_spec = knn_TN/float(knn_TN+knn_FP)\n",
    "print('KNN Specificity : {0:0.5f}'.format(knn_spec))\n",
    "knn_prec = knn_TP/float(knn_TP+knn_FP)\n",
    "print('KNN Precision : {0:0.5f}'.format(knn_prec))\n",
    "knn_recall = knn_TP/float(knn_TP+knn_FN)\n",
    "print('KNN Recall/Sensitivity : {0:0.5f}'.format(knn_recall))\n",
    "knn_f1s = 2*knn_recall*knn_prec/float(knn_recall+knn_prec)\n",
    "print('KNN F1-Score : {0:0.5f}'.format(knn_f1s))\n",
    "knn_tpr = knn_TP/float(knn_TP+knn_FN)\n",
    "print('KNN True Positive Rate : {0:0.5f}'.format(knn_tpr))\n",
    "knn_fpr = knn_FP/float(knn_FP+knn_TN)\n",
    "print('KNN False Positive Rate : {0:0.5f}'.format(knn_fpr))\n",
    "knn_res = classification_report(pred_knn, y_test)\n",
    "print(knn_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SUPPORT VECTOR MACHINE\n",
    "\n",
    "# fit the model\n",
    "model_svm = clf_svm.fit(X_train, y_train)\n",
    "pred_svm = model_svm.predict(X_test)\n",
    "# --- Model Accuracy\n",
    "svm_acc = accuracy_score(pred_svm, y_test)\n",
    "print('Model Accuracy: {:.5f}'.format(svm_acc))\n",
    "# --- Confusion Matrix\n",
    "svm_conmat = confusion_matrix(pred_svm, y_test)\n",
    "print(svm_conmat)\n",
    "display = ConfusionMatrixDisplay(svm_conmat, display_labels=[\"ARABICA\", \"ROBUSTA\"])\n",
    "display.plot(cmap=\"YlGnBu\")\n",
    "display.figure_.suptitle('Confusion Matrix')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "svm_TP = svm_conmat[0,0]\n",
    "svm_TN = svm_conmat[1,1]\n",
    "svm_FP = svm_conmat[0,1]\n",
    "svm_FN = svm_conmat[1,0]\n",
    "\n",
    "# --- Performance Metrics\n",
    "svm_acc = (svm_TP+svm_TN)/ float(svm_TP+svm_TN+svm_FP+svm_FN)\n",
    "print('SVM Accuracy : {0:0.5f}'.format(svm_acc))\n",
    "svm_error = (svm_FP+svm_FN)/ float(svm_TP+svm_TN+svm_FP+svm_FN)\n",
    "print('SVM Error : {0:0.5f}'.format(svm_error))\n",
    "svm_spec = svm_TN/float(svm_TN+svm_FP)\n",
    "print('SVM Specificity : {0:0.5f}'.format(svm_spec))\n",
    "svm_prec = svm_TP/float(svm_TP+svm_FP)\n",
    "print('SVM Precision : {0:0.5f}'.format(svm_prec))\n",
    "svm_recall = svm_TP/float(svm_TP+svm_FN)\n",
    "print('SVM Recall/Sensitivity : {0:0.5f}'.format(svm_recall))\n",
    "svm_f1s = 2*svm_recall*svm_prec/float(svm_recall+svm_prec)\n",
    "print('SVM F1-Score : {0:0.5f}'.format(svm_f1s))\n",
    "svm_tpr = svm_TP/float(svm_TP+svm_FN)\n",
    "print('SVM True Positive Rate : {0:0.5f}'.format(svm_tpr))\n",
    "svm_fpr = svm_FP/float(svm_FP+svm_TN)\n",
    "print('SVM False Positive Rate : {0:0.5f}'.format(svm_fpr))\n",
    "svm_res = classification_report(pred_svm, y_test)\n",
    "print(svm_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ROC-AUC Analysis\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='orange', linestyle='--')\n",
    "# --- Naive Bayes ---\n",
    "gnb_pred_proba = model_gnb.predict_proba(X_test)[::,1]\n",
    "fpr_gnb, tpr_gnb, _ = roc_curve(y_test,  gnb_pred_proba)\n",
    "lr_auc = roc_auc_score(y_test, gnb_pred_proba)\n",
    "plt.plot(fpr_gnb,tpr_gnb,label=\"Gaussian Naive-Bayes, AUC={:.5f}\".format(lr_auc))\n",
    "# --- Logistic Regression ---\n",
    "lr_pred_proba = model_lr.predict_proba(X_test)[::,1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test,  lr_pred_proba)\n",
    "lr_auc = roc_auc_score(y_test, lr_pred_proba)\n",
    "plt.plot(fpr_lr,tpr_lr,label=\"Logistic Regression, AUC={:.5f}\".format(lr_auc))\n",
    "# --- Decision Tree ---\n",
    "dt_pred_proba = model_dt.predict_proba(X_test)[::,1]\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test,  dt_pred_proba)\n",
    "dt_auc = roc_auc_score(y_test, dt_pred_proba)\n",
    "plt.plot(fpr_dt,tpr_dt,label=\"Decision Tree, AUC={:.5f}\".format(dt_auc))\n",
    "# --- Random Forest ---\n",
    "rf_pred_proba = model_rf.predict_proba(X_test)[::,1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test,  rf_pred_proba)\n",
    "rf_auc = roc_auc_score(y_test, rf_pred_proba)\n",
    "plt.plot(fpr_rf,tpr_rf,label=\"Random Forest, AUC={:.5f}\".format(rf_auc))\n",
    "# --- K-Nearest Neightbors ---\n",
    "knn_pred_proba = model_knn.predict_proba(X_test)[::,1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test,  knn_pred_proba)\n",
    "knn_auc = roc_auc_score(y_test, knn_pred_proba)\n",
    "plt.plot(fpr_knn, tpr_knn,label=\"K-Nearest Neighbors, AUC={:.5f}\".format(knn_auc))\n",
    "# --- Support Vector Machine ---\n",
    "svm_pred_proba = model_svm.predict_proba(X_test)[::,1]\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test,  svm_pred_proba)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_proba)\n",
    "plt.plot(fpr_svm, tpr_svm,label=\"Support Vector Machine, AUC={:.5f}\".format(svm_auc))\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=12)\n",
    "plt.legend(prop={'size': 9},loc=4)  #loc='lower right'\n",
    "plt.show()\n",
    "\n",
    "#https://www.imranabdullah.com/2019-06-01/Drawing-multiple-ROC-Curves-in-a-single-plot\n",
    "#https://www.geeksforgeeks.org/multiclass-receiver-operating-characteristic-roc-in-scikit-learn/\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#load-and-prepare-data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
